{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "394d9d93-2e5c-4419-b48b-5dc682c2c37b",
        "_uuid": "b4d887deb330df3f06decde04734ca0335358f23",
        "id": "F2O0fDd8VBu1"
      },
      "source": [
        "# Content\n",
        "1. Pendahuluan\n",
        "2. Teori algoritma back-propagation kesalahan\n",
        "3. Deskripsi database\n",
        "4. Implementasi Jaringan Saraf Back-propagation\n",
        "5. Kesimpulan\n",
        "***\n",
        "## 1. Pendahuluan\n",
        "\n",
        "Jaringan Saraf Back-Propagation adalah jaringan feed-forward dengan arsitektur yang cukup sederhana. Arsitektur jaringan terdiri dari lapisan input, satu atau lebih lapisan tersembunyi, dan lapisan output. Jenis jaringan ini dapat membedakan data yang tidak dapat dipisahkan secara linear. Kami menggunakan algoritma error back-propagation untuk menyetel jaringan secara iteratif.\n",
        "***\n",
        " ## 2. Teori algoritma back-propagation kesalahan\n",
        "\n",
        "Algoritma back-propagation kesalahan terdiri dari dua langkah besar:\n",
        "1. Meneruskan makanan dari input dari database ke lapisan input kemudian ke lapisan tersembunyi dan akhirnya ke lapisan output.\n",
        "2. Menghitung kesalahan output dan memberi makan mundur untuk menyetel variabel jaringan.\n",
        "***\n",
        "## 3. Deskripsi database\n",
        "\n",
        "Dalam contoh ini, kami akan menggunakan basis data Kanker Payudara Duke yang terdiri dari [86] entri dan [7129] atribut ditambah atribut kelas yang terletak di kolom pertama. Data ini bersifat numerik dan tidak memiliki nilai yang hilang.\n",
        "***\n",
        "## 4. Back-propagation Neural Network implementation\n",
        "\n",
        "Pertama-tama, kita perlu memuat basis data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "collapsed": true,
        "id": "M_Vd8stSVBu4",
        "trusted": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Database raw shape (86,7130)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np \n",
        "from sklearn.model_selection import train_test_split #library train_test_split untuk membagi data training dan data testing\n",
        "\n",
        "db = np.loadtxt(\"duke-breast-cancer.txt\")\n",
        "print(\"Database raw shape (%s,%s)\" % np.shape(db))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "collapsed": true,
        "id": "enaXPmf-VBu5"
      },
      "source": [
        "Sekarang kita harus mengacaknya dan kemudian membaginya menjadi 90% untuk pelatihan dan 10% untuk pengujian agar jaringan dapat melatih dirinya sendiri lebih baik. Jika diperlukan, Anda juga dapat menormalkan basis data tersebut."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "_cell_guid": "24bea183-2074-4d53-a47a-cf05bb5ec7ed",
        "_uuid": "762d37c4dae44319c9d2422e169d7ea0f33572a9",
        "collapsed": true,
        "id": "j0LlKi88VBu5",
        "trusted": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(77, 7129) (9, 7129)\n"
          ]
        }
      ],
      "source": [
        "np.random.shuffle(db) \n",
        "y = db[:, 0] #mengambil kolom pertama dari database sebagai target\n",
        "x = np.delete(db, [0], axis=1) #menghapus kolom pertama dari database sebagai input\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1) \n",
        "print(np.shape(x_train),np.shape(x_test)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b1339c51-6710-4bf3-89f9-d4a58f1efead",
        "_uuid": "22981874e171b499eb46ef87b768e9cd02f67d68",
        "id": "PfaVWW1TVBu5"
      },
      "source": [
        "Sekarang kita harus membuat vektor lapisan tersembunyi, matriks bobot, vektor lapisan output, dan matriks bobot tersembunyi. Kami memilih lapisan tersembunyi terdiri dari sejumlah [72] perceptron tersembunyi. Lapisan output perlu memiliki sejumlah perceptron yang sama dengan jumlah kelas. Matriks bobot akan memiliki bentuk berikut: baris = jumlah atribut basis data, kolom = jumlah perceptron lapisan tersembunyi, dan matriks bobot tersembunyi akan memiliki bentuk berikut: baris = panjang lapisan tersembunyi, kolom = jumlah perceptron lapisan output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "_cell_guid": "c56476bc-9ed6-4f59-adcc-05c1d7efffe8",
        "_uuid": "c6e92169cd8d40cfbd6535d89ef9d568ec7f080a",
        "collapsed": true,
        "id": "PAgnAfsdVBu6",
        "trusted": false
      },
      "outputs": [],
      "source": [
        "hidden_layer = np.zeros(72) #inisialisasi hidden layer dengan 72 neuron\n",
        "weights = np.random.random((len(x[0]), 72)) #inisialisasi bobot dengan nilai random\n",
        "output_layer = np.zeros(2) \n",
        "hidden_weights = np.random.random((72, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9f0f46d5-6522-4993-9cec-5e3ce2f04b04",
        "_uuid": "9e5dedcada121685d8b54cc88d9b367d824edb1c",
        "id": "VMw0ub6nVBu6"
      },
      "source": [
        "Untuk melanjutkan, kita perlu mengimplementasikan beberapa fungsi penting:\n",
        "\n",
        "1. Fungsi penjumlahan (Sum function)\n",
        "2. Fungsi aktivasi (Activation function)\n",
        "3. Fungsi SoftMax (SoftMax function)\n",
        "4. Fungsi Menghitung Ulang Bobot (Recalculate Weights function)\n",
        "5. Fungsi Back-propagation (Back-propagation function)\n",
        "\n",
        "## Sum function\n",
        "![sum.png](https://image.ibb.co/i3EM27/sum.png)\n",
        "- s_i = jumlah untuk perceptron ke-[i] dari lapisan tersebut.\n",
        "- Xi = input\n",
        "- Wi = bobot\n",
        "- Wj = bias\n",
        "- y = output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "_cell_guid": "64eef7a8-6c64-41c9-857b-8719e740acb9",
        "_uuid": "a9363b0d1930d5ab7bf109087c44f9f1f5378e04",
        "collapsed": true,
        "id": "To5XA7DVVBu6",
        "trusted": false
      },
      "outputs": [],
      "source": [
        "def sum_function(weights, index_locked_col, x):\n",
        "    result = 0\n",
        "    for i in range(0, len(x)): #perulangan untuk menghitung hasil perkalian antara input dan bobot\n",
        "        result += x[i] * weights[i][index_locked_col]\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "cc370a5d-bfe2-406d-8543-35b6558dc728",
        "_uuid": "56acfc5f17e7105d3cd4f2a4896dca97a7a48271",
        "id": "XaG86yFoVBu7"
      },
      "source": [
        "## Activation function\n",
        "![image.png](https://image.ibb.co/eTfYFS/g.png)\n",
        "- \\( g(s_i) \\) adalah aktivasi dari perceptron ke-\\(i\\) pada lapisan.\n",
        "- \\( s_i \\) adalah hasil dari fungsi jumlah untuk perceptron ke-\\(i\\) pada lapisan, yang dihitung menggunakan bobot dan input.\n",
        "- \\( \\tanh \\) adalah fungsi tangen hiperbolik, yang menghasilkan nilai di rentang \\((-1, 1)\\).\n",
        "- \\( 1.7159 \\) adalah konstanta untuk mengubah rentang fungsi tangen hiperbolik menjadi \\((-1.7159, 1.7159)\\). Ini merupakan pendekatan yang sering digunakan untuk mempercepat konvergensi jaringan selama pelatihan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "_cell_guid": "6c9963c8-0c5b-4b5d-8254-940017be5147",
        "_uuid": "4d8da27a9d20a0d9e22ccbc7f2e97a2ad1ce3d8d",
        "collapsed": true,
        "id": "fvv5mCgQVBu7",
        "trusted": false
      },
      "outputs": [],
      "source": [
        "def activate_layer(layer, weights, x): \n",
        "    for i in range(0, len(layer)): \n",
        "        layer[i] = 1.7159 * np.tanh(2.0 * sum_function(weights, i, x) / 3.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "909ef5c7-7017-4d03-943a-56eff9b91cd6",
        "_uuid": "a9824a7d2937bf0435e48419e7bc07d6803da551",
        "id": "IkWwly8EVBu8"
      },
      "source": [
        "## SoftMax function\n",
        "\n",
        "Fungsi softmax, atau fungsi eksponensial yang dinormalisasi, adalah generalisasi dari fungsi logistik yang \"menyempitkan\" vektor z berdimensi K dari nilai real sembarang menjadi vektor Ïƒ(z) berdimensi K dari nilai real dalam rentang (0, 1) yang jumlahnya adalah 1.\n",
        "- ![image.png](softmaxx.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "_cell_guid": "c33b200b-07e1-475a-9310-4b6486f36f46",
        "_uuid": "cd1e82c77d052992d5b8bfe9ea4793c7dae9fa82",
        "collapsed": true,
        "id": "rBypd-tGVBvK",
        "trusted": false
      },
      "outputs": [],
      "source": [
        "def soft_max(layer): \n",
        "    soft_max_output_layer = np.zeros(len(layer)) #inisialisasi output layer dengan nilai 0\n",
        "    for i in range(0, len(layer)):\n",
        "        denominator = 0 #denominator adalah nilai pembagi\n",
        "        for j in range(0, len(layer)):\n",
        "            denominator += np.exp(layer[j] - np.max(layer)) \n",
        "        soft_max_output_layer[i] = np.exp(layer[i] - np.max(layer)) / denominator #rumus softmax\n",
        "    return soft_max_output_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f4c83acf-fadf-4197-a8c3-f597fd487b3c",
        "_uuid": "f557cad437c5de3f5a4628d0efebbe0d8b5c84da",
        "id": "96p1B7gdVBvL"
      },
      "source": [
        "## Recalculate weights function\n",
        "Di sini kita menyetel bobot jaringan dan matriks bobot tersembunyi. Kita akan menggunakan ini di dalam fungsi backpropagation.\n",
        "- ![image.png](https://image.ibb.co/moBepn/w.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "_cell_guid": "8ee9f8b5-35a4-4a20-85b6-e13fc2c16db8",
        "_uuid": "a2d58312392a090b6f9c07b4c251bfae866aaefa",
        "collapsed": true,
        "id": "6peohZJuVBvL",
        "trusted": false
      },
      "outputs": [],
      "source": [
        "def recalculate_weights(learning_rate, weights, gradient, activation):\n",
        "    for i in range(0, len(weights)):\n",
        "        for j in range(0, len(weights[i])):\n",
        "            weights[i][j] = (learning_rate * gradient[j] * activation[i]) + weights[i][j]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "406650e7-9042-4718-91f7-7069deb4f395",
        "_uuid": "f0cbc7cdcd6412f74ba12921a20817ce5d9d51cf",
        "id": "-y2JXjhmVBvM"
      },
      "source": [
        "## Back-propagation function\n",
        "Dalam fungsi ini, kita mencari gradien lapisan output dan gradien lapisan tersembunyi untuk menghitung ulang bobot jaringan.\n",
        "- Rumus gradien lapisan output:\n",
        "- ![image.png](https://image.ibb.co/eJ9qUn/go.png)\n",
        "- Hidden gradient formula\n",
        "- ![image.png](https://image.ibb.co/mYQ3h7/gh.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "_cell_guid": "886bcb3a-4b24-4d2c-bb93-a932a0e5e5bf",
        "_uuid": "bf147c36b5709607dad90ab78749a77dea18f0d6",
        "collapsed": true,
        "id": "URubhiDOVBvM",
        "trusted": false
      },
      "outputs": [],
      "source": [
        "def back_propagation(hidden_layer, output_layer, one_hot_encoding, learning_rate, x): #one_hot_encoding adalah target, learning_rate adalah laju pembelajaran\n",
        "    output_derivative = np.zeros(2) #inisialisasi turunan output\n",
        "    output_gradient = np.zeros(2) #inisialisasi gradien output\n",
        "    for i in range(0, len(output_layer)): #perulangan untuk menghitung turunan output\n",
        "        output_derivative[i] = (1.0 - output_layer[i]) * output_layer[i]\n",
        "    for i in range(0, len(output_layer)): #perulangan untuk menghitung gradien output\n",
        "        output_gradient[i] = output_derivative[i] * (one_hot_encoding[i] - output_layer[i])\n",
        "    hidden_derivative = np.zeros(72) \n",
        "    hidden_gradient = np.zeros(72)\n",
        "    for i in range(0, len(hidden_layer)): #perulangan untuk menghitung turunan hidden layer\n",
        "        hidden_derivative[i] = (1.0 - hidden_layer[i]) * (1.0 + hidden_layer[i])\n",
        "    for i in range(0, len(hidden_layer)): #perulangan untuk menghitung gradien hidden layer\n",
        "        sum_ = 0 \n",
        "        for j in range(0, len(output_gradient)): \n",
        "            sum_ += output_gradient[j] * hidden_weights[i][j]\n",
        "        hidden_gradient[i] = sum_ * hidden_derivative[i]\n",
        "\n",
        "    #menghitung ulang bobot hidden layer dan output layer\n",
        "    recalculate_weights(learning_rate, hidden_weights, output_gradient, hidden_layer) \n",
        "    recalculate_weights(learning_rate, weights, hidden_gradient, x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d84f6360-946c-41a8-aeb0-15c07ddff96e",
        "_uuid": "3d8e2c2b5da99f9b0e1abb19b9ba7dcefb26e518",
        "id": "aUkAQ7BUVBvM"
      },
      "source": [
        "Next we can [one hot encode](https://www.quora.com/What-is-one-hot-encoding-and-when-is-it-used-in-data-science) our output and start training our network iterative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "_cell_guid": "9e2dbc9d-0f08-4c0b-94d7-31a4b90dc46c",
        "_kg_hide-input": false,
        "_uuid": "842e987aa6eeab97f21fceb01c49d1465983e9cd",
        "collapsed": true,
        "id": "he1CVJSOVBvM",
        "trusted": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP Correct answers while learning: 41 / 77 (Accuracy = 0.5324675324675324) on Duke breast cancer database.\n"
          ]
        }
      ],
      "source": [
        "one_hot_encoding = np.zeros((2,2)) #untuk mengubah target menjadi one hot encoding\n",
        "for i in range(0, len(one_hot_encoding)): \n",
        "    one_hot_encoding[i][i] = 1\n",
        "training_correct_answers = 0\n",
        "for i in range(0, len(x_train)): #perulangan untuk proses pembelajaran \n",
        "    activate_layer(hidden_layer, weights, x_train[i])\n",
        "    activate_layer(output_layer, hidden_weights, hidden_layer)\n",
        "    output_layer = soft_max(output_layer)\n",
        "    training_correct_answers += 1 if y_train[i] == np.argmax(output_layer) else 0\n",
        "    back_propagation(hidden_layer, output_layer, one_hot_encoding[int(y_train[i])], -1, x_train[i])\n",
        "print(\"MLP Correct answers while learning: %s / %s (Accuracy = %s) on %s database.\" % (training_correct_answers, len(x_train),\n",
        "                                                                                       training_correct_answers/len(x_train),\"Duke breast cancer\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "bfd53b22-e2fa-4dc6-9dfc-08ebd25355a4",
        "_uuid": "a07b936e15e43679d208ff3a2dab306ba861f11b",
        "id": "AibrYUNTVBvN"
      },
      "source": [
        "Akurasi pengujian bergantung pada matriks bobot yang dihasilkan secara acak dan laju pembelajaran. Menggunakan laju pembelajaran dan bobot yang berbeda akan menghasilkan akurasi yang berbeda pula."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "_cell_guid": "3e97419b-e5b8-4751-b1aa-b92adbdb7883",
        "_kg_hide-output": false,
        "_uuid": "d054f30b2e1514d48825906f72a667ae139dddda",
        "collapsed": true,
        "id": "ed7pEEymVBvN",
        "trusted": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP Correct answers while testing: 9 / 9 (Accuracy = 1.0) on Duke breast cancer database\n"
          ]
        }
      ],
      "source": [
        "testing_correct_answers = 0\n",
        "for i in range(0, len(x_test)):\n",
        "    activate_layer(hidden_layer, weights, x_test[i])\n",
        "    activate_layer(output_layer, hidden_weights, hidden_layer)\n",
        "    output_layer = soft_max(output_layer)\n",
        "    testing_correct_answers += 1 if y_test[i] == np.argmax(output_layer) else 0\n",
        "print(\"MLP Correct answers while testing: %s / %s (Accuracy = %s) on %s database\" % (testing_correct_answers, len(x_test),\n",
        "                                                                                     testing_correct_answers/len(x_test), \"Duke breast cancer\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "fb49e27e-f3f6-4743-b8ea-fb3634782a4e",
        "_uuid": "a1052057b9c6ab253b9758cbc8cc30707440b90d",
        "id": "rInZQO8ZVBvN"
      },
      "source": [
        "Pada set pengujian ini, akurasi dapat mencapai 100% bahkan dengan jumlah perceptron tersembunyi yang tepat dalam lapisan tersembunyi. Dalam contoh ini, kami menggunakan laju pembelajaran [-1] dengan total [72] perceptron tersembunyi dalam lapisan tersembunyi.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "96a1f6e2-6f22-4717-a614-590ee0b7776d",
        "_uuid": "aaf9f269d3c7400a9d9ac82ebdc1a960d0792016",
        "id": "KguqX9GlVBvN"
      },
      "source": [
        "***\n",
        "## 5.  Conclusion\n",
        "Dalam tes ini, kami telah menunjukkan bahwa jaringan saraf back-propagation berkinerja baik pada kumpulan data yang besar. Kinerjanya dapat ditingkatkan dengan mengubah jumlah neuron tersembunyi dan laju pembelajaran. Karena pelatihannya yang iteratif dan berbasis gradien, kecepatan umumnya jauh lebih lambat dari yang dibutuhkan, sehingga membutuhkan waktu yang cukup lama untuk dilatih pada kumpulan data yang sangat besar. Kami tidak dapat mengatakan bahwa ada jaringan yang sempurna untuk setiap jenis basis data. Jadi teruslah menguji data Anda pada berbagai jaringan saraf dan lihat mana yang paling cocok.\n",
        "\n",
        "Saya harap notebook ini membantu Anda memulai perjalanan Anda ke dunia pembelajaran mesin dan big data."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Back-Propagation Neural Network",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
